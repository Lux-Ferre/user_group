import asyncio
import requests
import json

from bs4 import BeautifulSoup
from playwright.async_api import async_playwright


async def get_soup_from_url(url: str) -> BeautifulSoup:
    async with async_playwright() as p:
        browser_type = p.chromium
        browser = await browser_type.launch_persistent_context("persistent_context")
        page = await browser.new_page()

        await page.goto(url)

        await page.wait_for_timeout(5000)   # Page JS takes time to load

        page_content = await page.content()
        soup = BeautifulSoup(page_content, 'html.parser')

    return soup


def get_product_list(soup: BeautifulSoup) -> list[BeautifulSoup | None]:
    products_element = soup.find("div", {"class": "grid__products"})
    if products_element:
        product_list = products_element.find_all("div", {"class": "grid-product"})
    else:
        product_list = []

    return product_list


def get_product_data(product_list: list[BeautifulSoup]) -> dict:
    product_data = {}
    for product in product_list:
        title = product.find("a", {"class": "grid-product__title"}).find("div").encode_contents().decode("utf-8")
        price_string = product.find("div", {"class": "grid-product__price-value"}).encode_contents().decode("utf-8")
        price_float = float(price_string[1:])
        product_data[title] = price_float

    return product_data


def scrape_pomprint_page(url: str) -> dict:
    soup = asyncio.run(get_soup_from_url(url))

    product_list = get_product_list(soup)

    product_data = get_product_data(product_list)

    return product_data


def generate_pomprint_urls() -> list[str]:
    data_file_js = requests.get("https://app.store.prositehosting.co.uk/data.js?ownerid=60810823&lang=en&token=11aa93419f9eeedcfc159ede498311c12a4ecec4&callback=window.ecwid_initial_data.data.doInit")

    raw_js_text = data_file_js.text

    raw_json = raw_js_text[:-1][38:]

    parsed_json = json.loads(raw_json)

    url_list = []

    for category in parsed_json["categories"]:
        category_list = [109697278, 109697256, 109633495]   # Handles general categories
        parent_category = category.get("parent", None)
        if parent_category in category_list:
            url_list.append(f'https://www.pomprintdesigns.co.uk/?store-page={category["autogeneratedSlug"]}-c{category["id"]}')

    return url_list


def scrape_all_pomprint():
    all_data = {}
    url_list = generate_pomprint_urls()

    print(url_list)

    for url in url_list:
        all_data[url] = scrape_pomprint_page(url)


    with open("scraped_data.json", mode="w+", encoding="utf-8") as f:
        json.dump(all_data, f, indent=4, sort_keys=True)

def main():
    scrape_all_pomprint()


if __name__ == "__main__":
    main()
